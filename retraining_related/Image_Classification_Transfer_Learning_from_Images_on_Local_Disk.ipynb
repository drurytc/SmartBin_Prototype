{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1wnG49WvyLjb"
      },
      "source": [
        "# Image Classification Transfer learning with dataset from local disk\n",
        "\n",
        "\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "Dox-68f_S51T"
      },
      "source": [
        "This Colab follows closely the https://www.tensorflow.org/lite/models/modify/model_maker/image_classification example, but with some small changes to upload custom images instead of downloading the example dataset\n",
        "\n",
        "Be careful that Colab limits your usage, so try to disconnect after retraining and downloading are finished, else you won't be able to access the perks of the GPU for a while\n",
        "\n",
        "(This is a copy of the contents of the colab link to save locally, you don't have to do anything here)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qvt6yfTQTL3D"
      },
      "source": [
        "# Step 0: Prerequisites"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V844ZqIT8ORm"
      },
      "outputs": [],
      "source": [
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vc1_ZmyD8Sxq"
      },
      "outputs": [],
      "source": [
        "!pip install -q tflite-model-maker"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M4_cVydA0C5X"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "import tensorflow as tf\n",
        "assert tf.__version__.startswith('2')\n",
        "\n",
        "from tflite_model_maker import model_spec\n",
        "from tflite_model_maker import image_classifier\n",
        "from tflite_model_maker.config import ExportFormat\n",
        "from tflite_model_maker.config import QuantizationConfig\n",
        "from tflite_model_maker.image_classifier import DataLoader\n",
        "\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bxSipBL-ydJf"
      },
      "source": [
        "# Step 1: Loading data from local disk into TF ImageDataset object\n",
        "**Before running, go to the folder icon and drag a zipped dataset into /content/. (This should be the default location when opeing the files tab, it contains sample_data by default, place the zipped data set next to sample_data)**\n",
        "\n",
        "The dataset must have images properly sorted into labeled sub directories. Each sub directory will correspond to a new class in the models head layer. For example, make sure all images of plastic bottles are in the directory dataset/plastic_bottles/. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8qp5pXNY0ehX"
      },
      "outputs": [],
      "source": [
        "!unzip -q Recyclables.zip"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9zibKssrBmyI"
      },
      "source": [
        "Set image path to the name of the uploaded data folder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vRkHfpyQ35BC"
      },
      "outputs": [],
      "source": [
        "image_path = 'Recyclables'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MTzKBSWaBuh9"
      },
      "source": [
        "Using tflife_model_maker/image_classifer/Dataloader to load the data from folder. This will automatically label the images with the name of thier resident directory. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7p7Aowyv__aB"
      },
      "outputs": [],
      "source": [
        "data = DataLoader.from_folder(image_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VTniC8nkCOmq"
      },
      "source": [
        "Showing an example of 25 images to make sure the data was loaded in properly"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q2JSQDAvAB4P"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(10,10))\n",
        "for i, (image, label) in enumerate(data.gen_dataset().unbatch().take(25)):\n",
        "  plt.subplot(5,5,i+1)\n",
        "  plt.xticks([])\n",
        "  plt.yticks([])\n",
        "  plt.grid(False)\n",
        "  plt.imshow(image.numpy(), cmap=plt.cm.gray)\n",
        "  plt.xlabel(data.index_to_label[label.numpy()])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jP8SaQn0A_NV"
      },
      "source": [
        "## Train test splitting\n",
        "Here we are splitting the data into training, validation, and test data, with a 0.8 to 0.1 to 0.1 split, respectively. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BBv75Xp-AVd9"
      },
      "outputs": [],
      "source": [
        "train_data, rest_data = data.split(0.8)\n",
        "validation_data, test_data = rest_data.split(0.5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0utAssQ5K7_o"
      },
      "outputs": [],
      "source": [
        "print(type(train_data))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Nv2ioIDCZdS"
      },
      "source": [
        "# Step 2: Customizing the TF model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rv0TnlxTDWqK"
      },
      "source": [
        "Choose pretrained model to customize. Options using ModelMaker are: \n",
        "* 'efficientnet_lite0',\n",
        "*'efficientnet_lite1',\n",
        "*'efficientnet_lite2',\n",
        "*'efficientnet_lite3',\n",
        "*'efficientnet_lite4',\n",
        "*'mobilenet_v2',\n",
        "*'resnet_50'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-SOCHrUPmIQR"
      },
      "source": [
        "Through our benchmarks, we prioritized non-recyclable waste accuracy to minimize false positives, and we found that mobilenet_v2 with 15 epochs is the way to go for our current dataset. Benchmarks for models that we tested are included in the GitHub repo under benchmarking sheet.xlsx(open this with Microsoft excel for images). If there are any significant changes to the dataset, please do step 3 for more benchmarking.:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j-UUFOfQnzdR"
      },
      "source": [
        "Note on the benchmarking sheet:\n",
        "\n",
        "The first page of the benchmarking sheet includes data that we looked at to decide on what model_spec we should use, and the second sheet, marked \"Hyperparams\" is the data we looked at to decide the hyperparameters we would use for our model (epochs and batch_size). feel free to mess around with these variables in the future to find a"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "08ylfAcoC4dL"
      },
      "outputs": [],
      "source": [
        "model_spec='mobilenet_v2'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OPxg5p1WDPb1"
      },
      "outputs": [],
      "source": [
        "model = image_classifier.create(\n",
        "  train_data, \n",
        "  validation_data=validation_data,\n",
        "  model_spec=model_spec,\n",
        "  epochs=20,\n",
        "  batch_size = 256\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z-UEBuEBFaMj"
      },
      "source": [
        "# Step 3: Evalutate the model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fV1mJFoumLAO"
      },
      "source": [
        "optional, do this to test out different specs.\n",
        "if you don't need to test them, skip this step\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7M4T4AJpFfER"
      },
      "outputs": [],
      "source": [
        "loss, accuracy = model.evaluate(test_data)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JunOq6s2Ftd_"
      },
      "outputs": [],
      "source": [
        "# A helper function that returns 'red'/'black' depending on if its two input\n",
        "# parameter matches or not.\n",
        "def get_label_color(val1, val2):\n",
        "  if val1 == val2:\n",
        "    return 'black'\n",
        "  else:\n",
        "    return 'red'\n",
        "\n",
        "# Then plot 100 test images and their predicted labels.\n",
        "# If a prediction result is different from the label provided label in \"test\"\n",
        "# dataset, we will highlight it in red color.\n",
        "plt.figure(figsize=(20, 20))\n",
        "predicts = model.predict_top_k(test_data)\n",
        "for i, (image, label) in enumerate(test_data.gen_dataset().unbatch().take(100)):\n",
        "  ax = plt.subplot(10, 10, i+1)\n",
        "  plt.xticks([])\n",
        "  plt.yticks([])\n",
        "  plt.grid(False)\n",
        "  plt.imshow(image.numpy(), cmap=plt.cm.gray)\n",
        "\n",
        "  predict_label = predicts[i][0][0]\n",
        "  color = get_label_color(predict_label,\n",
        "                          test_data.index_to_label[label.numpy()])\n",
        "  ax.xaxis.label.set_color(color)\n",
        "  plt.xlabel('Predicted: %s' % predict_label)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k8MoA4HbsHMZ"
      },
      "source": [
        "# Export the model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Gugoy_VmNm8"
      },
      "source": [
        "Run this to download the model as a .tflite file that you can load to the Raspberry pi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "33EPPMkasJx6"
      },
      "outputs": [],
      "source": [
        "model.export(export_dir='.', tflite_filename= f'{model_spec}.tflite')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nadN9uPeIgCK"
      },
      "outputs": [],
      "source": [
        "# Download the TFLite model to your local computer.\n",
        "from google.colab import files\n",
        "files.download(f'{model_spec}.tflite')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
